# mabert
A prototype: Multiple sequence Alignment using Bidirectional Encoder Representations from Transformers (MABERT). A BERT encodes the sequences, hierarchical clustering is then used to create a guide tree through which alignment is performed.
